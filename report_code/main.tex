\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage[hyphens]{url}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{svg}
\usepackage{multirow}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Agentic Open-Target Stance Detection with Finetuned Local LLMs
\thanks{Identify applicable funding source here. If none, delete this.}
}

\author{\IEEEauthorblockN{Author One}
\IEEEauthorblockA{\textit{Dept. of Computer Science} \\
\textit{University Name}\\
City, Country \\
email@address}
\and
\IEEEauthorblockN{Author Two}
\IEEEauthorblockA{\textit{Dept. of Computer Science} \\
\textit{University Name}\\
City, Country \\
email@address}
}

\maketitle

\section{Abstract}

Open-Target Stance Detection (OTSD) presents a unique challenge in natural language processing, requiring systems to identify targets and determine stances without predefined target lists. This paper presents a robust approach combining Parameter-Efficient Finetuning (PEFT) of local Large Language Models (LLMs) with a streamlined agentic workflow. We finetuned the Llama 3.1 8B model using Low-Rank Adaptation (LoRA) on a combined dataset of VAST and TSE examples. This finetuned model is integrated into a LangGraph-based agentic system featuring a three-stage pipeline: linguistic analysis, multi-hypothesis target generation, and stance classification. Our experimental results on diverse datasets demonstrate the effectiveness of this approach, achieving high target semantic similarity (up to 0.93) and competitive stance detection accuracy (up to 59.34\%) using locally hosted models. The system effectively handles both explicit and implicit targets, validating the synergy between task-specific finetuning and agentic reasoning.

\begin{IEEEkeywords}
stance detection, target detection, agentic ai, langgraph, large language models, llama3, finetuning, LoRA, local models
\end{IEEEkeywords}

\section{Introduction}

Social media platforms generate vast amounts of opinionated content daily. Analyzing this content requires automated systems capable of Stance Detection (SD)â€”determining whether an author supports, opposes, or remains neutral toward a topic. Traditional SD assumes the target is known beforehand. However, in realistic scenarios, the target is often implicit or not predefined, leading to the task of Open-Target Stance Detection (OTSD).

OTSD requires a system to first identify the target from the text and then classify the stance. For example, in the text "They really messed up this new patch, it's so buggy," the system must identify "new patch" as the target and "AGAINST" as the stance. This is particularly challenging when targets are implicit or require contextual reasoning.

While large proprietary models like GPT-4 excel at this task, they entail high costs and privacy concerns. This work explores the viability of using smaller, locally-hosted open-source models. We propose a hybrid approach that combines the generative capabilities of a finetuned Llama 3.1 8B model with the structured reasoning of an agentic workflow.

Our contributions are:
\begin{enumerate}
    \item A finetuning strategy using LoRA on Llama 3.1 8B for joint target-stance generation.
    \item A streamlined agentic architecture using LangGraph that leverages the finetuned model for robust inference.
    \item Empirical evaluation showing strong performance in target semantic similarity and stance accuracy across explicit and implicit datasets.
\end{enumerate}

\section{Methodology}

Our methodology integrates two key components: a finetuned local LLM adapted for the OTSD task, and an agentic workflow that orchestrates the inference process.

\subsection{Model Finetuning}

To adapt the Llama 3.1 8B model for OTSD, we employed Parameter-Efficient Finetuning (PEFT) using Low-Rank Adaptation (LoRA). Full finetuning of 8B parameter models is computationally expensive; LoRA mitigates this by freezing the pretrained weights and injecting trainable low-rank matrices into specific layers.

\subsubsection{Dataset Construction}
We constructed a combined training dataset by merging resources from established stance detection benchmarks:
\begin{itemize}
    \item \textbf{TSE Dataset}: Provides examples with explicitly mentioned targets.
    \item \textbf{VAST Dataset}: Offers a diverse range of topics and stances, including implicit targets.
\end{itemize}
The combined dataset was formatted into instruction-following pairs, teaching the model to extract the primary target and determine the stance (FAVOR, AGAINST, NONE) in a structured format.

\subsubsection{Training Configuration}
We utilized the Unsloth library for optimized training. The configuration included:
\begin{itemize}
    \item \textbf{Base Model}: Llama 3.1 8B (4-bit quantized).
    \item \textbf{LoRA Parameters}: Rank $r=16$, Alpha $\alpha=16$.
    \item \textbf{Target Modules}: q\_proj, k\_proj, v\_proj, o\_proj, gate\_proj, up\_proj, down\_proj.
    \item \textbf{Optimization}: AdamW 8-bit optimizer, max sequence length of 2048 tokens.
\end{itemize}
This finetuning process specialized the model for the specific output format and reasoning required for stance detection, significantly improving its zero-shot capabilities compared to the base model.

\subsection{Agentic Architecture}

We implemented a simplified agentic workflow using LangGraph to orchestrate the inference process. This architecture, illustrated in Figure~\ref{fig:simple_agent_arch}, decomposes the task into three linear stages to maximize stability and accuracy.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.48\textwidth]{simple_agent_arch.pdf}
    \caption{Simple Agent Architecture using LangGraph. The workflow consists of Linguistic Analysis, Target Detection, and Stance Detection nodes.}
    \label{fig:simple_agent_arch}
\end{figure}

The workflow consists of the following nodes:

\begin{enumerate}
    \item \textbf{Linguistic Analysis Agent}: Analyzes the input text for sentiment, tone, and stylistic features. This provides a contextual foundation for the subsequent steps, helping to resolve ambiguities in target identification.
    
    \item \textbf{Target Detection Agent}: Utilizing the finetuned model, this agent generates potential targets. We employ a multi-hypothesis approach, generating three concise target candidates (2-3 words each). This accounts for the inherent ambiguity in natural language, where a target might be referred to in multiple valid ways.
    
    \item \textbf{Stance Detection Agent}: This agent takes the primary target identified in the previous step and the original text to determine the final stance. The stance is classified as FAVOR, AGAINST, or NEUTRAL.
\end{enumerate}

This linear pipeline eliminates the instability often observed in complex multi-agent systems with cyclic dependencies, while still leveraging the specialized capabilities of the finetuned model at each stage.

\section{Experimentation}

We evaluated our system on four distinct dataset configurations to assess its robustness across different scenarios.

\subsection{Datasets}
\begin{itemize}
    \item \textbf{TSE Explicit}: Tweets where the target is explicitly mentioned.
    \item \textbf{TSE Implicit}: Tweets where the target is implied but not explicitly stated.
    \item \textbf{VAST Explicit}: A diverse dataset with explicit targets.
    \item \textbf{VAST Implicit}: A challenging subset where targets must be inferred from context.
\end{itemize}

\subsection{Evaluation Metrics}
We employed two primary metrics:
\begin{enumerate}
    \item \textbf{Stance Accuracy}: The percentage of correct stance classifications (FAVOR, AGAINST, NEUTRAL) compared to ground truth.
    \item \textbf{Target Semantic Similarity}: To evaluate target generation, we calculated the cosine similarity between the embeddings of the generated target and the ground truth target. This accounts for semantic equivalence (e.g., "COVID-19" vs "Coronavirus") that exact string matching would miss.
\end{enumerate}

\section{Results}

Table~\ref{tab:results} presents the performance of our Agentic Stance Detection system.

\begin{table}[htbp]
\caption{Performance Metrics on Evaluation Datasets}
\begin{center}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Dataset} & \textbf{Stance Accuracy} & \textbf{Target Similarity} \\
\hline
TSE Explicit & 44.04\% & 0.9311 \\
TSE Implicit & 47.50\% & 0.9203 \\
VAST Explicit & 55.77\% & 0.8957 \\
VAST Implicit & 59.34\% & 0.8603 \\
\hline
\end{tabular}
\label{tab:results}
\end{center}
\end{table}

\subsection{Analysis}

\textbf{Target Generation}: The system achieved exceptionally high target semantic similarity scores, ranging from 0.86 to 0.93. This indicates that the finetuning process successfully taught the model to identify the core topic of the text, even when it wasn't an exact string match to the ground truth. The multi-hypothesis generation strategy further ensured that the most relevant target was captured.

\textbf{Stance Detection}: Stance accuracy was competitive, particularly on the VAST datasets (up to 59.34\%). Interestingly, the system performed better on the VAST Implicit dataset than on the TSE Explicit dataset. This suggests that the model's reasoning capabilities, enhanced by the linguistic analysis stage, are robust enough to handle implicit contexts effectively. The lower accuracy on TSE Explicit might be attributed to domain-specific nuances or shorter text lengths typical of tweets, which provide less context for the model.

\textbf{Impact of Finetuning}: The integration of the finetuned model was crucial. Previous experiments with the base Llama 3.1 8B model (without finetuning) struggled to generate structured outputs or identify targets consistently. The PEFT adaptation ensured that the model followed the agentic instructions precisely.

\section{Conclusion}

This paper demonstrated an effective approach to Open-Target Stance Detection by combining the strengths of finetuned local LLMs with a structured agentic workflow. By finetuning Llama 3.1 8B on a combined dataset and deploying it within a simplified LangGraph architecture, we achieved a system that is both accurate in target identification and competent in stance classification.

Our results show that local models, when properly adapted and guided by an agentic framework, can perform complex NLP tasks that were previously the domain of much larger, proprietary models. Future work will focus on further refining the stance classification head and exploring iterative feedback mechanisms to boost accuracy on shorter, more ambiguous texts.

\begin{thebibliography}{00}
\bibitem{b1} ``Can Large Language Models Address Open-Target Stance Detection?,'' arXiv preprint arXiv:2409.00222, 2024. [Online]. Available: https://arxiv.org/abs/2409.00222

\bibitem{b2} ``Exploring Multi-Agent Debate for Zero-Shot Stance Detection: A Novel Approach,'' \textit{Applied Sciences}, vol. 15, no. 9, 2024. [Online]. Available: https://www.mdpi.com/2076-3417/15/9/4612

\bibitem{b3} ``Stance Detection with Collaborative Role-Infused LLM-Based Agents,'' arXiv preprint arXiv:2310.10467, 2023. [Online]. Available: https://arxiv.org/abs/2310.10467

\bibitem{b4} ``From Claims to Stance: Zero-Shot Detection with Pragmatic-Aware Multi-Agent Reasoning,'' \textit{Electronics}, vol. 14, no. 21, 2024. [Online]. Available: https://www.mdpi.com/2079-9292/14/21/4298

\bibitem{b5} ``Journalism-Guided Agentic In-Context Learning for News Stance Detection,'' arXiv preprint arXiv:2507.11049, 2025. [Online]. Available: https://arxiv.org/html/2507.11049v2

\bibitem{b6} ``Beyond Static Responses: Multi-Agent LLM Systems as a New Paradigm for Social Science Research,'' arXiv preprint arXiv:2506.01839, 2025. [Online]. Available: https://arxiv.org/abs/2506.01839

\bibitem{b7} ``Rethinking Modality Contribution in Multimodal Stance Detection via Dual Reasoning,'' arXiv preprint arXiv:2511.06057, 2025. [Online]. Available: https://arxiv.org/html/2511.06057v1

\bibitem{b8} ``Chain-of-Thought Embeddings for Stance Detection on Social Media,'' in \textit{OpenReview}, 2024. [Online]. Available: https://openreview.net/pdf?id=lqe06F5OiU

\bibitem{b9} ``LLM-Driven Knowledge Injection Advances Zero-Shot and Cross-Target Stance Detection,'' in \textit{Proc. NAACL}, 2024. [Online]. Available: https://aclanthology.org/2024.naacl-short.32/

\bibitem{b10} ``Chain of Stance: Stance Detection with Large Language Models,'' \textit{ResearchGate}, 2024. [Online]. Available: https://www.researchgate.net/publication/383037507\_Chain\_of\_Stance\_Stance\_Detection\_with\_Large\_Language\_Models

\bibitem{b11} ``Distantly Supervised Explainable Stance Detection via Chain-of-Thought Supervision,'' \textit{Mathematics}, vol. 12, no. 7, 2024. [Online]. Available: https://www.mdpi.com/2227-7390/12/7/1119

\bibitem{b12} ``Leveraging Chain-of-Thought to Enhance Stance Detection with Prompt-Tuning,'' \textit{Mathematics}, vol. 12, no. 4, 2024. [Online]. Available: https://www.mdpi.com/2227-7390/12/4/568

\bibitem{b13} ``Large Language Models Meet Stance Detection: A Survey of Tasks, Methods, Applications, Challenges and Future Directions,'' arXiv preprint arXiv:2505.08464, 2025. [Online]. Available: https://arxiv.org/abs/2505.08464

\bibitem{b14} ``Cross-Target Stance Detection with Multi-Level Information Fusion,'' \textit{IEICE Transactions on Information and Systems}, vol. E108.D, no. 8, 2024. [Online]. Available: https://www.jstage.jst.go.jp/article/transinf/E108.D/8/E108.D\_2024EDP7303/\_article

\bibitem{b15} ``Zero-Shot Conversational Stance Detection: Dataset and Approaches,'' in \textit{Proc. ACL Findings}, 2025. [Online]. Available: https://aclanthology.org/2025.findings-acl.168.pdf

\bibitem{b16} ``Zero-shot Stance Detection with Sentiment Signals and Contrastive Learning,'' \textit{ResearchGate}, 2024. [Online]. Available: https://www.researchgate.net/publication/397629407

\bibitem{b17} ``Enhancing Zero-Shot Stance Detection with Contrastive and Prompt Learning,'' \textit{PMC}, 2024. [Online]. Available: https://pmc.ncbi.nlm.nih.gov/articles/PMC11049083/

\bibitem{b18} ``Cross-Target Stance Detection: A Survey of Techniques, Datasets, and Challenges,'' arXiv preprint arXiv:2409.13594, 2024. [Online]. Available: https://arxiv.org/abs/2409.13594

\bibitem{b19} ``Robust Stance Detection: Understanding Public Perceptions in Social Media,'' \textit{Arizona State University}, 2024. [Online]. Available: https://asu.elsevierpure.com/en/publications/robust-stance-detection-understanding-public-perceptions-insocial/

\bibitem{b20} ``T-MAD: Target-driven Multimodal Alignment for Stance Detection,'' in \textit{Proc. EMNLP}, 2025. [Online]. Available: https://aclanthology.org/2025.emnlp-main.30.pdf

\bibitem{b21} ``Sign-Aware Graph Learning Framework for Stance Detection,'' \textit{IEEE Transactions}, 2024. [Online]. Available: https://ieeexplore.ieee.org/document/10446704/

\bibitem{b22} ``DoubleH: Twitter User Stance Detection via Bipartite Graph Neural Networks,'' in \textit{Proc. ICWSM}, 2024. [Online]. Available: https://ojs.aaai.org/index.php/ICWSM/article/view/31424

\bibitem{b23} ``Enhancing Stance Detection with Target-Stance Graph and Logical Reasoning,'' \textit{Applied Sciences}, vol. 15, no. 21, 2024. [Online]. Available: https://www.mdpi.com/2076-3417/15/21/11784

\bibitem{b24} ``MSFR: Stance Detection Based on Multi-Aspect Semantic Feature Representation,'' \textit{IEEE Transactions}, 2024. [Online]. Available: https://ieeexplore.ieee.org/document/10446704/

\end{thebibliography}

\end{document}
